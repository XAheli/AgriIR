#!/usr/bin/env python3
"""
Deterministic Citation Tracking System
Automatic citation generation without LLM dependency
"""

import re
import hashlib
from typing import List, Dict, Set, Tuple, Optional
from dataclasses import dataclass, field
from collections import defaultdict
import numpy as np
from sentence_transformers import SentenceTransformer
from difflib import SequenceMatcher
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class CitationMetadata:
    """Metadata for a citation source"""
    citation_id: str
    source_type: str  # 'database' or 'web'
    title: str
    url: str
    author: Optional[str] = None
    date: Optional[str] = None
    snippet: Optional[str] = None
    full_content: str = ""
    similarity_score: float = 0.0
    domain: Optional[str] = None
    chunk_id: Optional[str] = None


@dataclass
class SentenceCitation:
    """Maps a sentence to its source citations"""
    sentence: str
    citation_ids: List[str] = field(default_factory=list)
    similarity_scores: Dict[str, float] = field(default_factory=dict)
    start_pos: int = 0
    end_pos: int = 0


class CitationTracker:
    """
    Deterministic citation tracking system that doesn't rely on LLM
    Uses sentence similarity to track which sources were used
    """
    
    def __init__(self, similarity_threshold: float = 0.75, use_embeddings: bool = True):
        """
        Initialize citation tracker
        
        Args:
            similarity_threshold: Minimum similarity score to consider a match
            use_embeddings: Use sentence embeddings for similarity (more accurate but slower)
        """
        self.similarity_threshold = similarity_threshold
        self.use_embeddings = use_embeddings
        
        # Storage
        self.sources: Dict[str, CitationMetadata] = {}
        self.source_sentences: Dict[str, List[str]] = {}  # source_id -> sentences
        self.sentence_embeddings: Dict[str, np.ndarray] = {}  # sentence -> embedding
        
        # Citation tracking
        self.sentence_citations: List[SentenceCitation] = []
        self.citation_usage: Dict[str, int] = defaultdict(int)
        
        # Load embedding model if needed
        self.embedding_model = None
        if use_embeddings:
            try:
                logger.info("Loading sentence embedding model...")
                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                logger.info("Embedding model loaded successfully")
            except Exception as e:
                logger.warning(f"Failed to load embedding model: {e}")
                logger.info("Falling back to text-based similarity")
                self.use_embeddings = False
    
    def add_source(self, citation_id: str, source_type: str, content: str, 
                   title: str, url: str, **kwargs) -> None:
        """
        Add a source to the tracker
        
        Args:
            citation_id: Unique citation ID (e.g., 'DB-1-1', 'WEB-2-3')
            source_type: 'database' or 'web'
            content: Full content text
            title: Source title
            url: Source URL
            **kwargs: Additional metadata (author, date, etc.)
        """
        # Create metadata
        metadata = CitationMetadata(
            citation_id=citation_id,
            source_type=source_type,
            title=title,
            url=url,
            full_content=content,
            **{k: v for k, v in kwargs.items() if hasattr(CitationMetadata, k)}
        )
        
        self.sources[citation_id] = metadata
        
        # Split content into sentences
        sentences = self._split_into_sentences(content)
        self.source_sentences[citation_id] = sentences
        
        # Generate embeddings if enabled
        if self.use_embeddings and self.embedding_model:
            for sentence in sentences:
                if sentence not in self.sentence_embeddings:
                    try:
                        embedding = self.embedding_model.encode(sentence, convert_to_numpy=True)
                        self.sentence_embeddings[sentence] = embedding
                    except Exception as e:
                        logger.warning(f"Failed to embed sentence: {e}")
        
        logger.info(f"Added source {citation_id}: {len(sentences)} sentences")
    
    def track_text(self, generated_text: str) -> List[SentenceCitation]:
        """
        Track which sources were used in generated text
        
        Args:
            generated_text: Text generated by the system
            
        Returns:
            List of SentenceCitation objects mapping sentences to sources
        """
        self.sentence_citations = []
        
        # Split generated text into sentences
        generated_sentences = self._split_into_sentences(generated_text)
        
        current_pos = 0
        for sentence in generated_sentences:
            # Find sentence position in original text
            start_pos = generated_text.find(sentence, current_pos)
            end_pos = start_pos + len(sentence)
            current_pos = end_pos
            
            # Find matching sources for this sentence
            matches = self._find_matching_sources(sentence)
            
            if matches:
                citation = SentenceCitation(
                    sentence=sentence,
                    citation_ids=[m[0] for m in matches],
                    similarity_scores={m[0]: m[1] for m in matches},
                    start_pos=start_pos,
                    end_pos=end_pos
                )
                self.sentence_citations.append(citation)
                
                # Update usage counts
                for citation_id, _ in matches:
                    self.citation_usage[citation_id] += 1
        
        logger.info(f"Tracked {len(generated_sentences)} sentences, {len(self.sentence_citations)} with citations")
        return self.sentence_citations
    
    def insert_citations(self, text: str, style: str = "inline") -> str:
        """
        Automatically insert citations into text
        
        Args:
            text: Text to insert citations into
            style: Citation style ('inline', 'superscript', 'footnote')
            
        Returns:
            Text with citations inserted
        """
        # Track text first if not already done
        if not self.sentence_citations:
            self.track_text(text)
        
        # Sort citations by position (reverse to insert from end to start)
        sorted_citations = sorted(self.sentence_citations, key=lambda x: x.start_pos, reverse=True)
        
        result = text
        for citation in sorted_citations:
            if citation.citation_ids:
                # Format citation based on style
                if style == "inline":
                    citation_str = self._format_inline_citations(citation.citation_ids)
                elif style == "superscript":
                    citation_str = self._format_superscript_citations(citation.citation_ids)
                elif style == "footnote":
                    citation_str = self._format_footnote_citations(citation.citation_ids)
                else:
                    citation_str = self._format_inline_citations(citation.citation_ids)
                
                # Insert citation at the end of the sentence
                result = result[:citation.end_pos] + citation_str + result[citation.end_pos:]
        
        return result
    
    def verify_citations(self, text: str) -> Dict[str, any]:
        """
        Verify that all citations in text are valid and correctly formatted
        
        Args:
            text: Text with citations to verify
            
        Returns:
            Verification report with issues found
        """
        report = {
            'valid': True,
            'total_citations': 0,
            'valid_citations': 0,
            'invalid_citations': [],
            'missing_sources': [],
            'formatting_errors': []
        }
        
        # Extract all citation markers
        citation_pattern = r'\[([A-Z]+-\d+-\d+)\]'
        matches = re.finditer(citation_pattern, text)
        
        for match in matches:
            report['total_citations'] += 1
            citation_id = match.group(1)
            
            # Check if source exists
            if citation_id not in self.sources:
                report['valid'] = False
                report['invalid_citations'].append(citation_id)
                report['missing_sources'].append({
                    'citation_id': citation_id,
                    'position': match.start()
                })
            else:
                report['valid_citations'] += 1
        
        # Check for formatting issues (e.g., duplicate citations)
        citation_positions = defaultdict(list)
        for match in re.finditer(citation_pattern, text):
            citation_positions[match.group(1)].append(match.start())
        
        for citation_id, positions in citation_positions.items():
            if len(positions) > 5:  # Flag excessive usage
                report['formatting_errors'].append({
                    'citation_id': citation_id,
                    'count': len(positions),
                    'issue': 'excessive_usage'
                })
        
        return report
    
    def generate_bibliography(self, used_only: bool = True) -> str:
        """
        Generate a bibliography of all sources
        
        Args:
            used_only: Only include sources that were cited
            
        Returns:
            Formatted bibliography
        """
        bibliography = "## References\n\n"
        
        # Filter sources
        if used_only:
            sources_to_include = [
                (cit_id, self.sources[cit_id]) 
                for cit_id in self.citation_usage.keys() 
                if cit_id in self.sources
            ]
        else:
            sources_to_include = [(cit_id, meta) for cit_id, meta in self.sources.items()]
        
        # Sort by citation ID
        sources_to_include.sort(key=lambda x: x[0])
        
        # Format each source
        for citation_id, metadata in sources_to_include:
            usage_count = self.citation_usage.get(citation_id, 0)
            
            bib_entry = f"**[{citation_id}]** "
            
            if metadata.author:
                bib_entry += f"{metadata.author}. "
            
            bib_entry += f"*{metadata.title}*. "
            
            if metadata.date:
                bib_entry += f"({metadata.date}). "
            
            bib_entry += f"Retrieved from {metadata.url}"
            
            if used_only and usage_count > 0:
                bib_entry += f" (cited {usage_count} times)"
            
            bibliography += bib_entry + "\n\n"
        
        return bibliography
    
    def get_citation_stats(self) -> Dict[str, any]:
        """Get statistics about citation usage"""
        return {
            'total_sources': len(self.sources),
            'sources_cited': len(self.citation_usage),
            'total_citations': sum(self.citation_usage.values()),
            'sentences_with_citations': len(self.sentence_citations),
            'most_cited': sorted(
                self.citation_usage.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5],
            'uncited_sources': [
                cit_id for cit_id in self.sources.keys() 
                if cit_id not in self.citation_usage
            ]
        }
    
    # Helper methods
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """Split text into sentences"""
        # Simple sentence splitter (can be improved with NLTK/spaCy)
        # Handles common abbreviations
        text = text.strip()
        
        # Replace common abbreviations to avoid incorrect splits
        text = re.sub(r'\b(Dr|Mr|Mrs|Ms|Prof|Sr|Jr)\\.', r'\1<PERIOD>', text)
        text = re.sub(r'\b([A-Z])\\.', r'\1<PERIOD>', text)  # Handle initials
        
        # Split on sentence terminators
        sentences = re.split(r'[.!?]+\s+', text)
        
        # Restore periods
        sentences = [s.replace('<PERIOD>', '.') for s in sentences if s.strip()]
        
        # Filter out very short sentences (likely fragments)
        sentences = [s for s in sentences if len(s.split()) >= 3]
        
        return sentences
    
    def _find_matching_sources(self, sentence: str) -> List[Tuple[str, float]]:
        """
        Find sources that match this sentence
        
        Returns:
            List of (citation_id, similarity_score) tuples
        """
        matches = []
        
        if self.use_embeddings and self.embedding_model:
            # Use embedding-based similarity
            try:
                query_embedding = self.embedding_model.encode(sentence, convert_to_numpy=True)
                
                for citation_id, source_sentences in self.source_sentences.items():
                    max_similarity = 0.0
                    
                    for source_sentence in source_sentences:
                        if source_sentence in self.sentence_embeddings:
                            source_embedding = self.sentence_embeddings[source_sentence]
                            
                            # Compute cosine similarity
                            similarity = np.dot(query_embedding, source_embedding) / (
                                np.linalg.norm(query_embedding) * np.linalg.norm(source_embedding)
                            )
                            
                            max_similarity = max(max_similarity, similarity)
                    
                    if max_similarity >= self.similarity_threshold:
                        matches.append((citation_id, float(max_similarity)))
            
            except Exception as e:
                logger.warning(f"Embedding similarity failed: {e}, falling back to text similarity")
                return self._find_matching_sources_text(sentence)
        else:
            # Use text-based similarity
            return self._find_matching_sources_text(sentence)
        
        # Sort by similarity score
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Return top matches
        return matches[:3]  # Limit to top 3 sources per sentence
    
    def _find_matching_sources_text(self, sentence: str) -> List[Tuple[str, float]]:
        """Find matching sources using text-based similarity (fallback)"""
        matches = []
        sentence_lower = sentence.lower()
        
        for citation_id, source_sentences in self.source_sentences.items():
            max_similarity = 0.0
            
            for source_sentence in source_sentences:
                # Use SequenceMatcher for text similarity
                similarity = SequenceMatcher(
                    None, 
                    sentence_lower, 
                    source_sentence.lower()
                ).ratio()
                
                max_similarity = max(max_similarity, similarity)
            
            if max_similarity >= self.similarity_threshold:
                matches.append((citation_id, max_similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches[:3]
    
    def _format_inline_citations(self, citation_ids: List[str]) -> str:
        """Format citations in inline style"""
        return f" [{']['.join(citation_ids)}]"
    
    def _format_superscript_citations(self, citation_ids: List[str]) -> str:
        """Format citations in superscript style"""
        # Convert to superscript numbers (would need to map citation_ids to numbers)
        return f"<sup>[{']['.join(citation_ids)}]</sup>"
    
    def _format_footnote_citations(self, citation_ids: List[str]) -> str:
        """Format citations in footnote style"""
        return f"^[{']['.join(citation_ids)}]"


def main():
    """Example usage"""
    # Initialize tracker
    tracker = CitationTracker(similarity_threshold=0.7, use_embeddings=True)
    
    # Add sources
    tracker.add_source(
        citation_id="DB-1-1",
        source_type="database",
        content="Rice cultivation requires proper water management. Paddy fields need 4-5 inches of standing water during the vegetative growth stage.",
        title="Rice Cultivation Practices in India",
        url="https://example.com/rice-cultivation",
        author="Dr. A. Kumar",
        date="2024"
    )
    
    tracker.add_source(
        citation_id="WEB-1-1",
        source_type="web",
        content="Water management is crucial for rice farming. Studies show that optimal water levels increase yield by 20-30%.",
        title="Water Management for Rice Farming",
        url="https://example.com/water-management",
        date="2024"
    )
    
    # Simulate generated text
    generated_text = """
    Rice cultivation requires careful water management to ensure optimal growth. 
    Maintaining 4-5 inches of standing water during the growing season is essential. 
    Proper water management can increase yields significantly, with studies showing improvements of 20-30%.
    """
    
    # Track and insert citations
    text_with_citations = tracker.insert_citations(generated_text.strip())
    
    print("Original text:")
    print(generated_text)
    print("\nText with citations:")
    print(text_with_citations)
    print("\n" + tracker.generate_bibliography())
    print("\nStatistics:")
    print(tracker.get_citation_stats())


if __name__ == "__main__":
    main()
